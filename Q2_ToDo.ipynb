{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpzaPwugLYzI"
   },
   "source": [
    "======================================================\n",
    "# **Deep Learning Course** - Fall 2021 -25647\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15VGmzTSMRHP"
   },
   "source": [
    "======================================================\n",
    "### **Student Information:**\n",
    "* Name= Mohammad\n",
    "* Last Name= Fahim\n",
    "* ID= 99206099\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUuU85l7rg5P"
   },
   "source": [
    "# **Deep Crossentropy method**\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5m_7tNU0rg5Q",
    "outputId": "a79c1371-fc29-4577-ecd1-e1e47d2e7a33"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week1_intro/submit.py\n",
    "\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "yp54Mdhsrg5S",
    "outputId": "765d2f60-3ec7-494b-9af9-df8d87f209ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPxbTD5Org5S"
   },
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLVE-mQbrg5S",
    "outputId": "e15e9c29-e543-437b-f822-0c5ebc31ba36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(20, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CSFzTNyKrg5S"
   },
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "\n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(2,1,p=probs)[0]\n",
    "      \n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gIcetVTrg5T",
    "outputId": "b9cff4ea-3ccf-4ea9-c80f-9dd2ca49eb5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[ 9.5554581e-03  4.1174494e-02  2.9429482e-02 -2.8828064e-02]\n",
      " [ 1.0378948e-02 -1.5435687e-01  2.8852921e-02  2.7299300e-01]\n",
      " [ 7.2918111e-03 -3.4987837e-01  3.4312781e-02  5.7463479e-01]\n",
      " [ 2.9424363e-04 -5.4546416e-01  4.5805477e-02  8.7792671e-01]\n",
      " [-1.0615040e-02 -3.5099360e-01  6.3364007e-02  5.9998894e-01]]\n",
      "actions: [0, 0, 0, 1, 1]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peT2AiClrg5T"
   },
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZBccx26Jrg5U"
   },
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    \"\"\"\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "\n",
    "    buffer =  [states_batch[i] for i in range(len(states_batch)) if rewards_batch[i]>=reward_threshold] \n",
    "    elite_states = []\n",
    "    for i in buffer:\n",
    "        for j in i:\n",
    "            elite_states.append(j.tolist())\n",
    "   \n",
    "    buffer =  [actions_batch[i] for i in range(len(actions_batch)) if rewards_batch[i]>=reward_threshold] \n",
    "    elite_actions = []\n",
    "    for i in buffer:\n",
    "        for j in i:\n",
    "            elite_actions.append(j.tolist())\n",
    "       \n",
    "    return np.array(elite_states,dtype=np.float32), np.array(elite_actions,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6D6fsEJrg5U"
   },
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ICOgC6eJrg5V"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "id": "mG34D0XErg5V",
    "outputId": "6c312b58-4b19-416c-f01b-db4e255e2800"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56204/1984003575.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
      "/tmp/ipykernel_56204/1984003575.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
      "/tmp/ipykernel_56204/1984003575.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
      "/tmp/ipykernel_56204/1984003575.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
      "/tmp/ipykernel_56204/1984003575.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
      "/tmp/ipykernel_56204/1984003575.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
      "/tmp/ipykernel_56204/1984003575.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [ generate_session(env, agent) for _ in range(n_sessions)] \n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "    agent.fit(elite_states, elite_actions)\n",
    "\n",
    "    # show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpgRtQo9rg5W"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D9mDksKerg5W"
   },
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501,
     "resources": {
      "http://localhost:8080/videos/openaigym.video.0.65.video000064.mp4": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "mlSpMARWrg5W",
    "outputId": "0aa3a3bc-2dd6-49cb-b264-df1156cbcafa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.0.55775.video000064.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNVfnFTeSvrr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Q2_ToDo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
